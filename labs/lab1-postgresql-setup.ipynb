{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Configuração Interativa do Banco de Dados (PostgreSQL)\n",
    "\n",
    "Este notebook executa a configuração do banco de dados PostgreSQL de forma interativa. As células de código a seguir irão se conectar ao contêiner do banco de dados e executar os scripts de criação de tabelas (DDL) e inserção de dados (DML) usando Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inicializar os bancos de dados\n",
    "\n",
    "Etapa obrigatória, pois todos os serviços iniciam desligados para que o MYBinder consiga inicializar o Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ mkdir -p /home/jovyan/logs\n",
      "+ echo 'Starting services...'\n",
      "Starting services...\n",
      "+ nohup redis-server\n",
      "+ sudo /usr/sbin/sshd -f /etc/ssh/sshd_config\n",
      "+ echo 'Waiting for SSH port 8822 to open...'\n",
      "Waiting for SSH port 8822 to open...\n",
      "+ nohup /home/jovyan/resources/code-server-3.4.1/bin/code-server\n",
      "+ ss -tuln\n",
      "+ grep -q :8822\n",
      "+ echo 'SSH port 8822 is open.'\n",
      "SSH port 8822 is open.\n",
      "+ echo 'Waiting for SSH to be ready for authentication...'\n",
      "Waiting for SSH to be ready for authentication...\n",
      "+ ssh -o StrictHostKeyChecking=no -p 8822 jovyan@localhost exit\n",
      "+ echo 'SSH is ready for authentication.'\n",
      "SSH is ready for authentication.\n",
      "+ sudo pg_ctlcluster 14 main start\n",
      "Cluster is already running.\n",
      "+ sleep 1\n",
      "+ echo 'Waiting for PostgreSQL to be ready...'\n",
      "Waiting for PostgreSQL to be ready...\n",
      "+ pg_isready -h localhost -p 5432 -q\n",
      "+ echo 'PostgreSQL is ready.'\n",
      "PostgreSQL is ready.\n",
      "+ cd /tmp\n",
      "+ sudo -u postgres psql -c 'CREATE DATABASE postgres;'\n",
      "+ echo 'Database postgres already exists.'\n",
      "Database postgres already exists.\n",
      "+ sudo -u postgres psql -c 'CREATE SCHEMA IF NOT EXISTS public;'\n",
      "NOTICE:  schema \"public\" already exists, skipping\n",
      "CREATE SCHEMA\n",
      "+ sudo -u postgres psql -c 'CREATE USER postgres WITH PASSWORD '\\''postgres'\\'';'\n",
      "+ echo 'User postgres already exists.'\n",
      "User postgres already exists.\n",
      "+ sudo -u postgres psql -c 'ALTER USER postgres WITH PASSWORD '\\''postgres'\\'';'\n",
      "ALTER ROLE\n",
      "+ sudo -u postgres psql -c 'CREATE USER jovyan WITH SUPERUSER;'\n",
      "+ echo 'User jovyan already exists.'\n",
      "User jovyan already exists.\n",
      "+ echo 'Concedendo permissoes para o usuario...'\n",
      "Concedendo permissoes para o usuario...\n",
      "+ sudo -u postgres psql -c 'GRANT USAGE ON SCHEMA public TO postgres;'\n",
      "GRANT\n",
      "+ sudo -u postgres psql -c 'GRANT ALL ON ALL TABLES IN SCHEMA public TO postgres;'\n",
      "GRANT\n",
      "+ sudo -u postgres psql -c 'ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO postgres;'\n",
      "ALTER DEFAULT PRIVILEGES\n",
      "+ cd -\n",
      "/home/jovyan/work\n",
      "+ echo 'Formatting and starting Hadoop...'\n",
      "Formatting and starting Hadoop...\n",
      "+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      "+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      "+ export HADOOP_CONF_DIR=/home/jovyan/resources/hadoop-2.9.2/etc/hadoop\n",
      "+ HADOOP_CONF_DIR=/home/jovyan/resources/hadoop-2.9.2/etc/hadoop\n",
      "+ '[' '!' -d /tmp/hadoop-jovyan/dfs/name/current ']'\n",
      "+ echo 'Formatting HDFS...'\n",
      "Formatting HDFS...\n",
      "+ hdfs namenode -format -force -nonInteractive\n",
      "+ . /home/jovyan/resources/hadoop-2.9.2/etc/hadoop/hadoop-env.sh\n",
      "++ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      "++ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      "++ export 'HADOOP_CLIENT_OPTS=-Djava.net.preferIPv4Stack=true '\n",
      "++ HADOOP_CLIENT_OPTS='-Djava.net.preferIPv4Stack=true '\n",
      "++ export 'HADOOP_OPTS=-Djava.library.path=/home/jovyan/resources/hadoop-2.9.2/lib/native '\n",
      "++ HADOOP_OPTS='-Djava.library.path=/home/jovyan/resources/hadoop-2.9.2/lib/native '\n",
      "++ export HADOOP_COMMON_LIB_NATIVE_DIR=/home/jovyan/resources/hadoop-2.9.2/lib/native\n",
      "++ HADOOP_COMMON_LIB_NATIVE_DIR=/home/jovyan/resources/hadoop-2.9.2/lib/native\n",
      "++ export 'YARN_OPTS= -Djava.library.path=/home/jovyan/resources/hadoop-2.9.2/lib/native'\n",
      "++ YARN_OPTS=' -Djava.library.path=/home/jovyan/resources/hadoop-2.9.2/lib/native'\n",
      "+ start-dfs.sh\n",
      "+ start-yarn.sh\n",
      "+ echo 'Waiting for NameNode process to start...'\n",
      "Waiting for NameNode process to start...\n",
      "+ jps\n",
      "+ grep -q NameNode\n",
      "+ echo 'NameNode process started.'\n",
      "NameNode process started.\n",
      "+ echo 'Waiting for NameNode port 9000 to open...'\n",
      "Waiting for NameNode port 9000 to open...\n",
      "+ ss -tuln\n",
      "+ grep -q :9000\n",
      "+ echo 'NameNode port 9000 is open.'\n",
      "NameNode port 9000 is open.\n",
      "+ echo 'Waiting for HDFS to exit safe mode...'\n",
      "Waiting for HDFS to exit safe mode...\n",
      "+ hdfs dfsadmin -safemode get\n",
      "+ grep -q 'Safe mode is OFF'\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/bin/entrypoint.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conexão e Execução dos Scripts\n",
    "\n",
    "A célula abaixo contém todo o processo:\n",
    "1.  Importa as bibliotecas necessárias.\n",
    "2.  Define as queries DDL e DML.\n",
    "3.  Estabelece uma conexão com o contêiner `petshop_db` (o nome do serviço no `docker-compose`).\n",
    "4.  Cria um cursor e executa as queries.\n",
    "5.  Confirma as transações e fecha a conexão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# As credenciais e o host são baseados no arquivo docker-compose.txt\n",
    "DB_HOST = \"localhost\" # Nome do serviço no Docker Compose\n",
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_USER_PWD = \"postgres\"\n",
    "\n",
    "DDL_SCRIPT = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS tutor (\n",
    "    tutor_id SERIAL PRIMARY KEY,\n",
    "    nome VARCHAR(255) NOT NULL,\n",
    "    email VARCHAR(255) UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS pet (\n",
    "    pet_id SERIAL PRIMARY KEY,\n",
    "    tutor_id INTEGER NOT NULL REFERENCES tutor(tutor_id),\n",
    "    nome VARCHAR(100) NOT NULL,\n",
    "    especie VARCHAR(50) NOT NULL,\n",
    "    tipo_pelo VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS agendamento (\n",
    "    agendamento_id SERIAL PRIMARY KEY,\n",
    "    pet_id INTEGER NOT NULL REFERENCES pet(pet_id),\n",
    "    tipo_servico VARCHAR(100) NOT NULL,\n",
    "    data_agendamento TIMESTAMP WITH TIME ZONE NOT NULL,\n",
    "    status VARCHAR(50) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS produto (\n",
    "    produto_id SERIAL PRIMARY KEY,\n",
    "    nome_produto VARCHAR(255) NOT NULL,\n",
    "    categoria VARCHAR(100),\n",
    "    preco NUMERIC(10, 2) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS compra (\n",
    "    compra_id SERIAL PRIMARY KEY,\n",
    "    tutor_id INTEGER NOT NULL REFERENCES tutor(tutor_id),\n",
    "    produto_id INTEGER NOT NULL REFERENCES produto(produto_id),\n",
    "    data_compra DATE NOT NULL,\n",
    "    quantidade INTEGER NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DML_SCRIPT = \"\"\"\n",
    "INSERT INTO tutor (nome, email) VALUES\n",
    "('Ana Carolina', 'ana.carolina@email.com'),\n",
    "('Bruno Martins', 'bruno.martins@email.com')\n",
    "ON CONFLICT (email) DO NOTHING;\n",
    "\n",
    "INSERT INTO pet (tutor_id, nome, especie, tipo_pelo) VALUES\n",
    "(1, 'Bidu', 'Cão', 'Longo'),\n",
    "(1, 'Luna', 'Gato', 'Curto'),\n",
    "(2, 'Thor', 'Cão', 'Longo');\n",
    "\n",
    "INSERT INTO agendamento (pet_id, tipo_servico, data_agendamento, status) VALUES\n",
    "(1, 'Banho e Tosa Completa', '2025-04-10 14:00:00', 'Realizado'),\n",
    "(1, 'Banho e Tosa Completa', '2025-05-11 14:00:00', 'Realizado'),\n",
    "(1, 'Banho e Tosa Completa', '2025-06-12 14:00:00', 'Realizado'),\n",
    "(3, 'Banho', '2025-07-01 11:00:00', 'Realizado');\n",
    "\n",
    "INSERT INTO produto (nome_produto, categoria, preco) VALUES\n",
    "('Ração para Cães de Pelo Longo', 'Alimentação', 75.50),\n",
    "('Shampoo Hipoalergênico para Cães', 'Higiene', 30.00);\n",
    "\n",
    "INSERT INTO compra (tutor_id, produto_id, data_compra, quantidade) VALUES\n",
    "(1, 1, '2025-06-15', 1), (1, 2, '2025-06-15', 1), (2, 1, '2025-06-22', 1);\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_USER_PWD)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    print(\"Executando script DDL (criação de tabelas)...\")\n",
    "    cur.execute(DDL_SCRIPT)\n",
    "    print(\"DDL executado com sucesso.\")\n",
    "    \n",
    "    print(\"Executando script DML (inserção de dados)...\")\n",
    "    # Limpa as tabelas antes de inserir para garantir que o script seja idempotente\n",
    "    cur.execute(\"TRUNCATE TABLE agendamento, compra, pet, tutor, produto RESTART IDENTITY CASCADE;\")\n",
    "    cur.execute(DML_SCRIPT)\n",
    "    print(\"DML executado com sucesso.\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Transação commitada.\")\n",
    "    \n",
    "except psycopg2.OperationalError as e:\n",
    "    print(f\"Erro de conexão: {e}\")\n",
    "    print(\"Verifique se os contêineres Docker estão em execução ('docker-compose up -d') e se o nome do host do banco de dados ('{DB_HOST}') está correto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn is not None:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        print(\"Conexão fechada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verificação\n",
    "\n",
    "Execute a célula abaixo para se conectar novamente e fazer uma consulta `SELECT` para verificar se os dados foram inseridos corretamente na tabela `agendamento`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_USER_PWD)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"SELECT * FROM agendamento;\")\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    print(\"Agendamentos encontrados:\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn is not None:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
